
-------------------------------------------------------------------------------------------------------------------------------
                                CI-CD OVERVIEW
-------------------------------------------------------------------------------------------------------------------------------

Continuos Integration:
    Push the code to Code commit/ github etc.
    Once code pushed, build/test server process the code. 

Continuos Delivery/Deployment:
    Continuos delivery involves manual step. 
    Continuos deployment is fully automated. 

Code Repository:AWS Code Commit, Git Hub
Build & Test:   AWS Code Build , Jenkins, Bamboo 
Provision:      AWS Elastic Bean Stalk 
Deploy:         AWS Code Deploy (User managed EC2, On Prem, Lambda, ECS)
Orchestrate:    AWS Code Pipeline 

-------------------------------------------------------------------------------------------------------------------------------

Code Commit: 
    It is private fully managed AWS git repository. 
    It is like Git Hub, Bit bucket.
    Code is encrypted and store under the account. 

Code Commit - Create First Repository & HTTPS Configuration:
    It can be connected through HTTPS & SSH Connection.
    SSH is not enabled for root account. 
    Under IAM User -> security credentials -> SSH Keys or HTTPS Git credential for Code Commit. 
    These credentials are used for push or pull from repository. 

    Code Commit -> Create Repository -> (Repository Name) -> Done. 
    Code Commit -> Repository -> View Repository 
    Clone URL gives the repository URL which will copied. 

Code Commit - Clone, Add, Commit, Push:
    git status          -> Shows status whether tracked or untracked. 
    git add .           -> Add files to staging area. 
    git commit -m 'msg' -> Commit the change in local git. 
    git push            -> Push to the repository. During push, asks for username and password. 

Code Commit - Branches and Pull Requests:
    git checkout -b branch_Name     -> It creates new branch and switch to new branch. 
    git branch branch_Name          -> Create a new branch. 
    git checkout branch_Name        -> Switch to new branch. 

    1. Created the new branch and modified with new feature. 
    2. Create Pull request (Merge) -> Merge the new feature branch to master branch. 
    3. In create pull request, select source as 'new feature branch' and destination as 'master' branch. 
    4. If no merge conflicts, will allow to create pull request. 
    5. From pull request section, Reviewer click 'Merge' to accept pull request. (Here have default option to delete the new-feature branch if required)  

Code Commit - Securing the repository and Branches: 
    It can be done by creating the policy to explicit deny to secure master branch. 
    Available in : https://docs.aws.amazon.com/codecommit/latest/userguide/how-to-conditional-branch.html
    Note: In below policy given for main branch only, Need to add master branch. 

                {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Effect": "Deny",
                        "Action": [
                            "codecommit:GitPush",
                            "codecommit:DeleteBranch",
                            "codecommit:PutFile",
                            "codecommit:MergeBranchesByFastForward",
                            "codecommit:MergeBranchesBySquash",
                            "codecommit:MergeBranchesByThreeWay",
                            "codecommit:MergePullRequestByFastForward",
                            "codecommit:MergePullRequestBySquash",
                            "codecommit:MergePullRequestByThreeWay"
                        ],
                        "Resource": "arn:aws:codecommit:us-east-1:*:*",
                        "Condition": {
                            "StringEqualsIfExists": {
                                "codecommit:References": [
                                    "refs/heads/main",
                                    "refs/heads/master"
                                ]
                            },
                            "Null": {
                                "codecommit:References": "false"
                            }
                        }
                    }
                ]
            }


    It failed with below error, so not allowing to push to master branch:

        error: remote unpack failed: internal error
        To https://git-codecommit.us-east-1.amazonaws.com/v1/repos/devops-code-commit-demo
        ! [remote rejected] master -> master (unpacker error)
        error: failed to push some refs to 'https://git-codecommit.us-east-1.amazonaws.com/v1/repos/devops-code-commit-demo'


    Code Commit - Triggers and Notifications:
        Notification - If any process like push, pull etc, it can be notified by using SNS. 
        Trigger - Same as notification but inaddition to SNS it allows to trigger Lambda. 
        Cloud watch Event - It can also done here by select source as code commit and target as any like SNS, Lambda etc. 

        Code Commit -> Settings -> Notifications Tab:
            Name, Events, SNS Target to select. 

        Code Commit -> Settings -> Trigger Tab: 
            Can select SNS or Lambda. 
        
        Event Bridge -> Rules -> Create Rule: 
            Name, Service Provider, Target 
    
    Code Commit - AWS Lambda: 
        https://docs.aws.amazon.com/codecommit/latest/userguide/how-to-notify-lambda.html
        
        1. Created the lambda function with trigger as code commit. 
        2. If any change in events in code commit, triggered the lambda. 
        3. Verified in cloud watch logs. 


-------------------------------------------------------------------------------------------------------------------------------

Code Build:
    It is fully managed build service like Jenkins. 
    Leverages Docker under the hood. 
    Source code from S3, Code Commit, Code Pipeline etc. 
    Build instruction defined in buildspec.yml file. 
    Output to S3 and cloud watch logs. 
    Can integrate with Event bridge to detect failures. 
    SNS & Lambda integrations. 

Code Build - First Build: 
    code build -> build projects -> 
    Sources - No sources/S3/Code Commit/Git hub/Bit bucket. 
    Reference Type can be Branch/Git tag/ Commit ID 
    Once build created, click 'start build' to run the build.                                                   


Code Build - buildspec.yml file: 
    It can be placed in S3 or root of source directory.


        version: 0.2                    # represent buildspec version. recommended to use 0.2 
        run-as: Linux-user-name         # optional specific to linux. 
        env:
        shell: shell-tag
        variables:
            key: "value"
            key: "value"
        parameter-store:
            key: "value"
            key: "value"
        exported-variables:
            - variable
            - variable
        secrets-manager:
            key: secret-id:json-key:version-stage:version-id
        git-credential-helper: no | yes

        proxy:
        upload-artifacts: no | yes
        logs: no | yes

        batch:
        fast-fail: false | true
        # build-list:
        # build-matrix:
        # build-graph:
                
        phases:
        install:
            run-as: Linux-user-name
            on-failure: ABORT | CONTINUE
            runtime-versions:
            runtime: version
            runtime: version
            commands:
            - command
            - command
            finally:                # this will be executed if previous is failed or success. 
            - command
            - command
        pre_build:
            run-as: Linux-user-name
            on-failure: ABORT | CONTINUE
            commands:
            - command
            - command
            finally:
            - command
            - command
        build:
            run-as: Linux-user-name
            on-failure: ABORT | CONTINUE
            commands:
            - command
            - command
            finally:
            - command
            - command
        post_build:
            run-as: Linux-user-name
            on-failure: ABORT | CONTINUE
            commands:
            - command
            - command
            finally:
            - command
            - command
        reports:
        report-group-name-or-arn:
            files:
            - location
            - location
            base-directory: location
            discard-paths: no | yes
            file-format: report-format
        artifacts:              
        files:
            - location
            - location
        name: artifact-name
        discard-paths: no | yes
        base-directory: location
        exclude-paths: excluded paths
        enable-symlinks: no | yes
        s3-prefix: prefix
        secondary-artifacts:
            artifactIdentifier:
            files:
                - location
                - location
            name: secondary-artifact-name
            discard-paths: no | yes
            base-directory: location
            artifactIdentifier:
            files:
                - location
                - location
            discard-paths: no | yes
            base-directory: location
        cache:
        paths:
            - path
            - path


Code Build - Docker, ECR & buildspec.yml file: 
    Code build used to build docker image and push to ECR. 
    
    1. Created the Dockerfile and buildspec.yml file. 
    2. Docker File: 
        FROM node:12-alpine
        RUN apk add --no-cache python3 g++ make
        WORKDIR /app
        COPY . .
        RUN yarn install --production
        CMD ["node", "src/index.js"]
    3. buildspec.yml: 
        version: 0.2
        phases:
        pre_build:
            commands:
            - echo Logging in to Amazon ECR...
            - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
        build:
            commands:
            - echo Build started on `date`
            - echo Building the Docker image...          
            - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .
            - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG      
        post_build:
            commands:
            - echo Build completed on `date`
            - echo Pushing the Docker image...
            - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG

    4. zip myzip.zip Dockerfile buildspec.yml 
    5. Use the environemental variables IMAGE_REPO_NAME=ECS Repository Name , IMAGE_TAG=latest version. 
    6. After build completed, ECR -> Repositories -> Images. 


Code Build - Environmental Variable and Parameter Store:
    https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-env-vars.html
    Link has list of environmental variables can use. 
    printenv in buildspec.yml (under commands) file prints all environmental variables. 
    environment variables can be given in buildspec file or override in console. 
    Parameters can be place from Systems Manager Parameter Store or Secrets Manager. 

Code Build - Artifacts & S3: 
    1. Include the artifacts in buildspec.yaml file. 
    2. In code build console, update to include the artifacts by giving s3.  
    3. In code build, start the build. 
    4. Artifacts created in S3. 

Code Build - Cloud watch Events, Cloudwatch Logs, Cloud watch metrics & Triggers:
    Code build -> View Projects -> edit -> Logs: 
        can select the cloudwatch logs and also s3 bucket to store logs. 
    
    Cloud watch -> Metrics -> Code build -> Select by Project or Account level. 
    Metrics can export to dashboard. 

    Cloud watch -> Events -> Rules: (Now changed to Amazon event bridge): 
        Event bridge -> Name, Event Pattern or Schedule (use cron to run at specific time) -> create Rule. 
    
Code Build - Validating code commit Pull Requests: 
    https://aws.amazon.com/blogs/devops/validating-aws-codecommit-pull-requests-with-aws-codebuild-and-aws-lambda/


-------------------------------------------------------------------------------------------------------------------------------

Code Deploy:
    EC2 or On-prem machine must running code deploy agent. 
    Agent continuosly polls code deploy for work. 
    code deploy has appspec.yml file. 
    Application is pulled from s3 or git hub. 
    Ec2 instances are group by deployment group. 
    It can integrate with pipeline. 
    Blue-Green works only with EC2 (not on-prem) 
    It support for Lambda, EC2. 

    Code + appspec.yml to S3 <->(Pulled by agent) EC2+agent. So EC2 requires access to read from S3. 

Code Deploy - EC2 Setup: 
    1. Create EC2 instance with TAGS mandatory. Tags are used by deployment group in code deploy service. 
    2. Create a service role with S3 access which requires to pull code_appspec.yml file from S3. 
    3. Install the code deploy agent in EC2. Either after ssh or use in user data field. 
            sudo yum update -y
            sudo yum install -y ruby wget
            wget https://aws-codedeploy-eu-west-1.s3.eu-west-1.amazonaws.com/latest/install
            chmod +x ./install
            sudo ./install auto
            sudo service codedeploy-agent status

Code Deploy - Application, Deployment Groups & FIrst Deployment: 
    1. Created the role (Allow code deploy to access EC2).
    2. Created the application. 
    3. Create the deployment group: 
            Name, Deployment type (Inplace or Blue green), Deployment Settings (Allatonce, oneatatime, halfatatime)
    4. Upload the code + appspecfile in zip to S3. 
            aws deploy push --application-name CodeDeployDemo --s3-location s3://aws-devops-course-stephane/codedeploy-demo/app.zip --ignore-hidden-files --region eu-west-1 --profile aws-devops            
    5. Create deployment: 
            s3 bucket location which contain code and then create deployment. 

    Note: TO check whether code deploy agent is properly installed. If not installed, then deploy will timeout with error. 

Code Deploy - Deployment Groups: 
    Under application, can create multiple deployment group with different tags. 
    This helps to separate for dev, prod instances. 
    During deploy, can select the specific deployment group for deployment. 

Code Deploy - Deployment Group Configurations: 
    Deployment Type: 
        Inplace - In existing instances, update the applications. 
        Blue Green  - Create new instances through manually or AutoScaling options. 
    
    Deployment Configurations: 
        AllatOnce, OneataTime, HalfataTime, Manually create deployment configurations. 
    
    Loadbalancer: 
        For blue-green, it is mandatory. 
        For inplace, it is optional. 

Code Deploy - appspec.yml file: 

    https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file.html

    NOte: Since run as root, no need of sudo in scripts. 

    version: 0.0
    os: linux
    files:
    - source: /
        destination: /var/www/html/WordPress
    hooks:
    BeforeInstall:
        - location: scripts/install_dependencies.sh
        timeout: 300
        runas: root
    AfterInstall:
        - location: scripts/change_permissions.sh
        timeout: 300
        runas: root
    ApplicationStart:
        - location: scripts/start_server.sh
        - location: scripts/create_test_db.shhttps://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html

    Hooks availabel different for , Inplace, Blue green original & replacement, Lambda  & ECS. 
    Few environmental variables are available like APPLICATION_NAME, DEPLOYMENT_ID
    
    if [ "$DEPLOYMENT_GROUP_NAME" == "Staging" ]
    then
        sed -i -e 's/Listen 80/Listen 9090/g' /etc/httpd/conf/httpd.conf
    fi
        timeout: 300
        runas: root
    ApplicationStop:
        - location: scripts/stop_server.sh
        timeout: 300
        runas: root
        

Code Deploy - Hooks & Environmental Variables: 
    https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file-structure-hooks.html

    Hooks availabel different for , Inplace, Blue green original & replacement, Lambda  & ECS. 
    Few environmental variables are available like APPLICATION_NAME, DEPLOYMENT_ID, DEPLOYMENT_GROUP_NAME, DEPLOYMENT_GROUP_ID, LIFECYCLE_EVENT 
    
    if [ "$DEPLOYMENT_GROUP_NAME" == "Staging" ]
    then
        sed -i -e 's/Listen 80/Listen 9090/g' /etc/httpd/conf/httpd.conf
    fi


Code Deploy - Cloud watch, Alarm, Trigger:
    Code Deploy -> Deployment groups -> Advanced Option -> Trigger 
    Code Deploy -> Deployment groups -> Advanced Option -> Alarm 
    Event bridge -> Code build -> Target can be any. 

Code Deploy - Rollbacks: 
    Code Deploy -> Deployment groups -> Advanced Option -> Rollbacks. 
    1. Rollback when deployment fails. 
    2. Rollback when alarm threshold are met. (This can use to monitor cpu utiliation, if more than to rollback)

Code Deploy - On Premise Setup: 
    https://docs.aws.amazon.com/codedeploy/latest/userguide/instances-on-premises.html

    Step 1 – Configure each on-premises instance, register it with CodeDeploy, and then TAG it.
    Step 2 – Deploy application revisions to the on-premises instance.

    1. use IAM User ARN  for authenticate request. -> Best for smaller instances. 
    2. use IAM role ARN for authenticate request. -> This is secure and complex. 

Code Deploy - Deploy to Lambda: 
    https://docs.aws.amazon.com/codedeploy/latest/userguide/applications-create-lambda.html

    hooks: 
        beforeallowtraffic functionname
        afterallowtraffic functionname 
    
    1. Create a service role for code-deploy for lambda. 
    2. Create the application. 
    3. Creaet the deployment group. 
    4. Deployment type: 
            allataonce
            canary - shifts in two increment 
            linear - shifts in equal increment. 
    5. Hooks contains beforeallowtraffic & afterallowtraffic. 


-------------------------------------------------------------------------------------------------------------------------------

Code Pipeline: 
    It is CI-CD Orchestrate tool. 
    Source : S3, Code Commit, ECR, Git hub, Bitbucket. 
    Build: Code Build, Jenkins
    Test: 3rd party tools, 
    Deploy: Code deploy, Cloud formation, Elastic bean stalk, ECS, S3 etc.

    It is made up of stages and each stages have sequential or parallel actions. 
    Can have manual approval process. 
    For each stage, generates output artifacts which will pass as input artifacts to next stage. 
    ATlest 2 stage is mandatory. 

Code Pipeline - Code Commit & Code Deploy: 
    In source, can select code commit, give the repository and branch details. 
    Note: Pipeline can created for 1 branch only. 
    Change detection Options: 
        Amazon cloudwatch events (recommended and automatically detect changes)
        AWS Code pipeline  (It periodically checks for changes)

    In code pipeline, can deploy to another region. 

Code Pipeline - Adding Code Build: 
    Can edit code pipeline. 
    Stage can be like source, build, test etc 
    Action group can be parallel or sequential. 

Code Pipeline - Artifacts, Encryption & S3: 
    Code pipeline -> Advanced setting: 
    S3: 
        Default location or Custom Location (recommended)    
    Key: 
        Default AWS Managed key or Customer managed key 

Code Pipeline - Manual approval steps:
    Under pipeline -> edit stage -> Manual approval stage. 
    Can select SNS topic to send notification. 
    
Code Pipeline - Cloud watch events integration: 
    During pipeline creation, it automatically create rules in event bridge. 
    Also can create our own rule, to choose target. 

Code Pipeline - Stage actions , Sequential & Parallel: 
    It consists of stages like source, build etc. 
    Sequential actions -> It process sequentially 
    Parallel actions -> It process parallel. 
    runOrder 1 
    runOrder 2 (It can be multiple and run parallel)
    runOrder 3 (It run after 2 and multiple can run parallel)

Code Pipeline - All Integrations: 
    https://docs.aws.amazon.com/codepipeline/latest/userguide/best-practices.html

    Build - Code build -> Generate artifacts 
    Test - Code build -> Does NOT generate artifacts. 

    Deploy -> Cloud formation (Comman use cases) 


Code Pipeline - Custom Action jobs with Lambda: 
    https://docs.aws.amazon.com/codepipeline/latest/userguide/actions-invoke-lambda-function.html

    1. Created the lambda service role. 
    2. Created the lambda function. 
    3. In code pipeline, INvoke a lambda function. 

Code Pipeline - Cloud Formation: 
    https://docs.aws.amazon.com/codepipeline/latest/userguide/tutorials-cloudformation.html


-------------------------------------------------------------------------------------------------------------------------------

Code Star - Overview: 
    Just upload a project and Code star will create the pipeline automatically which includes code commit, code build, code deploy etc depends upon the project. 


-------------------------------------------------------------------------------------------------------------------------------

Jenkins Architecture: 
    Jenkins is open source CI-CD tool.
    Can replace code build, deploy, code pipeline. 
    Must deploy in master slave configuration. 
    Have jenkinsfile similar to buildspec.yml file. 
    Jenkins can replace code pipeline or other like code build, code deploy etc. 

Jenkins - Setup on EC2: 
    #!/bin/bash
    # setup Jenkins on EC2
    sudo yum update -y
    sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo
    sudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key
    sudo yum install java-1.8.0 -y
    sudo amazon-linux-extras install epel
    sudo yum install jenkins -y
    sudo service jenkins start

    sudo cat /var/lib/jenkins/secrets/initialAdminPassword

    ec2-public-ip-address:8080 port 

    
Jenkis - AWS Plugins: 
    In Jenkins, have different plugins to integrate with AWS like AWS EC2, Code Pipeline etc. 

White Papers to Read: 
    Whitepapers to Read
        At this stage, please have a look at the following whitepapers to better help you in preparing for your certification. You don't need to read everything, just understand the general idea and skim through.

        MUST READ - Blue/Green Deployments on AWS
        https://d1.awsstatic.com/whitepapers/AWS_Blue_Green_Deployments.pdf

        RECOMMENDED - Practicing Continuous Integration Continuous Delivery on AWS
        https://d1.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf

        RECOMMENDED - Jenkins on AWS
        https://d1.awsstatic.com/whitepapers/DevOps/Jenkins_on_AWS.pdf

        OPTIONAL - Introduction to DevOps on AWS
        https://d1.awsstatic.com/whitepapers/AWS_DevOps.pdf

        OPTIONAL - Development and Test on AWS
        https://d1.awsstatic.com/whitepapers/aws-development-test-environments.pdf


-------------------------------------------------------------------------------------------------------------------------------
                    CONFIGURATION MANAGEMENT & INFRASTRUCTURE AS CODE
-------------------------------------------------------------------------------------------------------------------------------

Cloud Formation: 
    Infrastructure as code 
    version control 
    Cant modify the existing stack. Can reupload again. 

Cloud Formation - Status: 
    CREATE_IN_PROGRESS 
    CREATE_COMPLETE 
    CREATE_FAILED
    UPDATE_IN_PROGRESS
    UPDATE_COMPLETE
    UPDATE_COMPLETE_CLEANUP_IN_PROGRESS 
    UPDATE_ROLLBACK_COMPLETE
    UPDATE_ROLLBACK_FAILED 
    DELETE_IN_PROGRESS
    DELETE_COMPLETE
    DELETE_FAILED
    ROLLBACK_IN_PROGRESS 
    ROLLBACK_COMPLETE 
    ROLLBACK_FAILED 


Cloud Formation - Create stacks hands on: 

    Cloudformation -> create stack -> S3 URL or Upload template. 
    Tags - Apply to the underlying resources. 
    Permissions - policy 
    Stack Failure - Roll back or Preserve. 
    Stack Policy - Defines the resources that want to protect from unintentional updates. 
    Timeout 
    Notifications 
    Termination protection 

    Estimate cost option. 


Cloud Formation - Update and Delete Stack: 
    Modify allow to upload new template or replaceexisting template. 
    Delting the stack, delete the underlying resources. 

Cloud Formation Parameters: 
    Parameters help to input custom values to stack. Some inputs cannot be determine at ahead of time. 

    Pseudo parameter are used to get the default values:  It refer by using !Ref AWS:AccountId 
        AWS::AccountId 
        AWS::NotificationARNs 
        AWS::NoValue 
        AWS::Region 
        AWS::StackId 
        AWS::StackName 

    Parameters:
        InstanceTypeParameter:
            Type: String
            Default: t2.micro
            AllowedValues:
            - t2.micro
            - m1.small
            - m1.large
            Description: Enter t2.micro, m1.small, or m1.large. Default is t2.micro.
            
Cloud Formation Resources: 

    It helps to create the resources. 
    AWS::aws-product-name::data-type-name 

    Resources: 
        myEC2:
            Type: AWS::EC2::Instance
            Properties: 
            ImageId: 'ami-0ed9277fb7eb570c9'
            InstanceType: !Ref InstanceTypeParameter

    Can create dynamic resource: 
        No, cannot generate. Everything has to be declared. 
    
    Is every AWS service supported: 
        Almost. For unavailable can use Lambda custom resources. 

Cloud Formation Mappings: 
    Used for known value in advance. 
    It is key value pair based. 

    !FindInMap[map_name, top_level_key, 2nd_level_key]      -> To retrieve the values from map. 

    Mappings: 
        Mapping01: 
            Key01: 
            Name: Value01
            Key02: 
            Name: Value02
            Key03: 
            Name: Value03
            
    RegionMap: 
        us-east-1:
            HVM64: ami-0ff8a91507f77f867
            HVMG2: ami-0a584ac55a7631c0c
        us-west-1:
            HVM64: ami-0bdb828fd58c52235
            HVMG2: ami-066ee5fd4a9ef77f1
        eu-west-1:
            HVM64: ami-047bb4163c506cd98
            HVMG2: ami-0a7c483d527806435
        ap-northeast-1:
            HVM64: ami-06cd52961ce9f0d85
            HVMG2: ami-053cdd503598e4a9d
        ap-southeast-1:
            HVM64: ami-08569b978cc4dfa10
            HVMG2: ami-0be9df32ae9f92309
                

Cloud Formation - Outputs: 
    If output is export (export name), then can import in another stack. (!importvalue export-name) 
    It enables cross stack. 
    Cant delete a stack if output is references in another stack. 

    Outputs: 
        Outputdisplayavailabilityzone: 
            Description: Output value description
            Value:  !GetAtt myEC2.AvailabilityZone
            Export: 
            Name: Availability-zone
        Outputdisplayinstanceid: 
            Description: Output value description
            Value:  !Ref myEC2
            Export: 
            Name: Instance-ID 

Cloud Formation - Conditions: 
    Can define the condition, if condition is true then only resource or output can be created. 
    Condition can reference another condition, parameter value or mapping. 

Cloud Formation Intrinsic Functions: 
        Fn::And
        Fn::Equals
        Fn::If
        Fn::Not
        Fn::Or
    Fn::Base64 -> returns base64 representation of input string. used to pass user data. 
    Fn::Ref or  !Ref   -> In resources, reference the resource ID. In parameters, references the value. 
    Fn:GetAtt or !GetAtt -> To get the attributes of the resources. 
    Fn::FindInMap or !FindInMap -> !FindInMap [map-name, top-key, 2nd-key]
    Fn::Join -> !Join [delimeter, [list of values ]]
    Fn::Sub ->  substutute 

Cloud Formation - User data: 
    It must be under Fn::Base64 
    User data is stored under /var/log/cloud-init log or /var/log/cloud-init-output.log 

          UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -xe
          yum update -y 
          yum install cloud-init -y
          yum install httpd -y

Cloud Formation - cfn-init: 
    AWS::CloudFormation::Init must be in METADATA of a RESOURCE.
    It helps to make complex configuration readable. 
    EC2 instance query the cloudformation template to get the init data. 
    Logs captured in /var/log/cfn-init logs. 

Cloud Formation - cfn signal and wait conditions: 
    After cfn-init, still dont know whether ec2 metadata are properly installed or not. 
    for this, cfn-signal is used to tell cloudformation stack about the success. 
    Need to define WaitCondition, it blocks template from process and wait for signal. 
    cfn-signal to process followed by cfn-init. 

Cloud Formation - wait signal trouble shoot: 
    cfn init helper script not installed. 
    check the /var/log/cloud-init.log or cfn-init.log 
    disable rollback on failure to check the logs. 
    verify has internet connection. 

Cloud Formation - rollbacks: 
    During stack creation -> Stack failure options: 
        1. Rollback all stack resources. 
        2. Preserve successfully provisioned resources. 

Cloud Formation - Nested Stacks: 
    Nested stacks are stacks are created separately and referenced in stack. 
    As code grows and separate stacks for network, server, database etc. reference the stack with in another stack. 

    AWS::CloudFormation::Stack 
    CAPABILITY_AUTO_EXPAND 
    IAM_CAPABILITY 

Cloud formation - Change Sets: 
    It helps to verify the change before implement the stack. 
    Cloudformation -> During create process -> Create change set .
    After, Under change sets -> Execute to run the stack. 

Cloud Formation - Deletion Policy: 
    Retain 
    Snapshot 
    Delete 
    DeletionPolicy: Retain

Cloud Formation - Termination Protection: 
    Cloud Formation -> Creation -> Stack Creation Options -> Termination Protection (Enabled or Disabled)


Cloud Formation - Parameters from SSM: 

    Type:   AWS::SSM::Parameter                   -> To create the parameter. 
    Type:   AWS::SSM::Parameter::Value<String>    -> To get the value         
            AWS::SSM::Parameter::Value<List<String>>
            AWS::SSM::Parameter::Value<Any AWS type>
            'AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>'


Cloud Formation - Public Parameters from SSM: 
    aws ssm get-parameters-by-path --path /aws/service/ami-amazon-linux-latest --query 'Parameters[].Name' 
    This command helps to get the list of parameters.  Use this in the Default value. 

Cloud Formation - DependsOn: 
    Resources are created parallely. 
    DependsOn helps to create dependency between resources. 

Cloud Formation - Deploying Lambda Function: 
    Role ARN is required. 
    handler - index.handler_name 
    In lambda, 4000 characters have inline. Only node.js and python allowed as inline. 
    CAPABILITY_IAM is required when create the IAM role. 

    To get the source from S3 bucket: 
        place the code in index.py file and zipped to s3 bucket. 
              Code: 
                S3Bucket: devops-code-build-image-code-source
                S3Key: lambda-code.zip
                S3ObjectVersion: pXPqiF6GWRdBg3TKjZlHoNhCTKcB7qHh

Cloud Formation - Custom Resources: 
    Custom resources used in below scenarios: 
        1. Provisioning AWS resources that are not supported in cloud formation. 
        2. Provisioning non AWS Resources. 
        3. Perform provisioning steps not related to infrasture. 
                ex: initialize the database. 
    
    It consists of: 
        1. Create the logic for custom resources. 
        2. Deploy the custom resource to Lambda function. 
        3. Use the custom resource in cloud formation template that references lambda function or SNS topic. 
        
        To use a custom resource in a CloudFormation stack, you need to create a resource of either type AWS::CloudFormation::CustomResource or Custom::<YourName>. 
        ServiceToken: ARN of Lambda function. 

        Cloudformation runs logic at anytime during create , update and delete stacks. 


Cloud Formation - Drift Detection: 
    Cloudformation -> Stack actions -> Detect drift 
    Cloudformation -> Stack actions -> View drift results 

    If any change in cloudformation template and actual infrastructure. then capture in drift detection. 

Cloud Formation - Insufficient Capabilities Exception: 
    CAPABILITY_IAM or CAPABILITY_NAMED_IAM (for custom resources) -> To create IAM resources.  (InsufficientCApabilitiesException)
    CAPABILITY_AUTO_EXPAND -> For nested stack. 

Cloud Formation - cfn hup and metadata: 
    If any change in metadata, cfn-hub will detect the metadata changes with default interval of 15 mins and run the cloudformation::init metadata again. 
    /etc/cfn/cfn-hup.conf 
    /etc/cfn/hooks.d/cfn-auto-reloader.conf 

Cloud Formation - Stack Policies: 
    It provides fail safe mechanism to prevent accidental deletion. 
    It helps to prevent update or delee through stack policy. 
    It allow to update but during process failed with error "Action denied by stack policy: Statement [#1] does not allow [Update:*] for resource [*];"


-------------------------------------------------------------------------------------------------------------------------------

Elastic Bean Stalk: 
    





